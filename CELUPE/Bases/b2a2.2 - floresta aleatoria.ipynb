{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Floresta aleat√≥ria\n",
    "==================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O algoritmo da floresta aleat√≥ria\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√≥s vimos no notebook anterior o algoritmo de √°rvore de decis√£o. Ele gera modeloz relativamente simples e explic√°veis, por√©m a performance destes modelos muitas vezes deixa a desejar.\n",
    "\n",
    "Mas e se montarmos um comit√™ (*ensemble*) contendo diversas √°rvores de decis√£o onde cada uma realiza sua previs√£o individual; podemos considerar que cada uma dessas previs√µes s√£o &ldquo;votos&rdquo; e considerando todos os votos n√≥s podemos chegar em uma resposta final. Ser√° que juntar modelos com relativa baixa performance em um comit√™ pode nos ajudar a melhorar a nossa previs√£o?\n",
    "\n",
    "A resposta √© *sim*! üéâ\n",
    "\n",
    "O nome do algoritmo descrito acima √© &ldquo;floresta aleat√≥ria&rdquo;. √â uma &ldquo;floresta&rdquo; pois √© feita de diversas *√°rvores* de decis√£o. √â &ldquo;aleat√≥ria&rdquo; pois o processo de construir cada uma das √°rvores de decis√£o desta floresta envolve amostragem dos exemplos e das features.\n",
    "\n",
    "Para uma fundamenta√ß√£o te√≥rica mais aprofundada, assista ao v√≠deo sobre o tema do [StatQuest](https://youtu.be/J4Wdy0Wc_xQ).\n",
    "\n",
    "Para usar o `scikit-learn` para treinar um modelo de floresta aleat√≥ria, n√≥s vamos seguir o mesmo procedimento que usamos nos notebooks anteriores.\n",
    "\n",
    "Vamos primeiro carregar os dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 61455\n",
    "DATASET_NAME = \"diamonds\"\n",
    "FEATURES = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "TARGET = [\"price\"]\n",
    "\n",
    "df = sns.load_dataset(DATASET_NAME)\n",
    "\n",
    "indices = df.index\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size=TAMANHO_TESTE, random_state=SEMENTE_ALEATORIA\n",
    ")\n",
    "\n",
    "df_treino = df.loc[indices_treino]\n",
    "df_teste = df.loc[indices_teste]\n",
    "\n",
    "# observe que usamos o .values aqui pois queremos apenas os valores\n",
    "X_treino = df_treino.reindex(FEATURES, axis=1).values\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values\n",
    "X_teste = df_teste.reindex(FEATURES, axis=1).values\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos treinar o modelo! Note que passamos o valor da semente aleat√≥ria para o argumento `random_state` na hora que criamos o modelo, assim como fizemos com a √°rvore de decis√£o no notebook anterior. A explica√ß√£o √© a mesma, retorne ao notebook de √°rvore de decis√£o caso n√£o se recorde. Outro detalhe √© que o `scikit-learn` d√° um aviso quando tentamos treinar este modelo caso os nossos targets (`y_treino` e `y_teste`) sejam arrays com mais de uma dimens√£o (isto √©, caso seu atributo `shape` tenha 2 ou mais elementos). Para evitar esse problema, os arrays em quest√£o foram transformados para arrays unidimensionais com o m√©todo `ravel`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48546, 1) (5394, 1)\n",
      "(48546,) (5394,)\n",
      "\n",
      "[1077.97        777.26        785.86809524 ...  493.72        735.89\n",
      "  923.07      ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# alterando o formato do target\n",
    "print(y_treino.shape, y_teste.shape)\n",
    "y_treino = y_treino.ravel()\n",
    "y_teste = y_teste.ravel()\n",
    "print(y_treino.shape, y_teste.shape)\n",
    "\n",
    "# cria o modelo\n",
    "modelo_rf = RandomForestRegressor(random_state=SEMENTE_ALEATORIA)\n",
    "\n",
    "# treina o modelo\n",
    "modelo_rf.fit(X_treino, y_treino)\n",
    "\n",
    "# realiza uma previs√£o usando o modelo treinado\n",
    "previsao = modelo_rf.predict(X_teste)\n",
    "print()\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos checar a performance do nosso modelo de floresta aleat√≥ria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo √°rvore de decis√£o foi de 1384.6366214316938 d√≥lares.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_verdadeiro = y_teste\n",
    "y_previsao = modelo_rf.predict(X_teste)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "\n",
    "print(f\"O RMSE do modelo √°rvore de decis√£o foi de {RMSE} d√≥lares.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O RMSE do modelo de floresta aleat√≥ria foi de 1385 d√≥lares! At√© agora este √© o melhor RMSE de um modelo padr√£o sem alterar os hiperpar√¢metros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperpar√¢metros\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo da floresta aleat√≥ria tem os mesmos hiperpar√¢metros do algoritmo da √°rvore de decis√£o e mais alguns outros. Todos eles podem ser conferidos na [documenta√ß√£o](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html). Um novo hiperpar√¢metro muito importente √© o `num_estimators` que controla o n√∫mero de √°rvores que ir√£o compor o comit√™ (por padr√£o esse valor √© de 100).\n",
    "\n",
    "Fique atento que o argumento `n_jobs` deste algoritmo *n√£o √© um hiperpar√¢metro*, mas sim o controle de como os c√°lculos ser√£o executados. Por padr√£o, o `scikit-learn` usa apenas um n√∫cleo de CPU para induzir sua floresta aleat√≥ria. Isso pode ser muito lento! Considere aumentar esse valor se voc√™ tiver capacidade computacional para tal.\n",
    "\n",
    "O c√≥digo abaixo testa tr√™s hiperpar√¢metros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo RF usando n_estimators=10 max_leaf_nodes=None e max_depth=None foi de 1440.74 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=100 max_leaf_nodes=None e max_depth=None foi de 1384.64 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=300 max_leaf_nodes=None e max_depth=None foi de 1377.99 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=10 max_leaf_nodes=None e max_depth=3 foi de 1418.18 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=100 max_leaf_nodes=None e max_depth=3 foi de 1417.28 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=300 max_leaf_nodes=None e max_depth=3 foi de 1418.01 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=10 max_leaf_nodes=6 e max_depth=None foi de 1463.91 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=100 max_leaf_nodes=6 e max_depth=None foi de 1461.31 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=300 max_leaf_nodes=6 e max_depth=None foi de 1462.44 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=10 max_leaf_nodes=6 e max_depth=3 foi de 1463.91 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=100 max_leaf_nodes=6 e max_depth=3 foi de 1461.31 d√≥lares.\n",
      "O RMSE do modelo RF usando n_estimators=300 max_leaf_nodes=6 e max_depth=3 foi de 1462.44 d√≥lares.\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "NUM_ARVORES = [10, 100, 300]\n",
    "NUM_FOLHAS = [None, 6]\n",
    "NUM_PROFUNDIDADE = [None, 3]\n",
    "\n",
    "for n_folhas, n_profundidade, n_arvores in product(\n",
    "    NUM_FOLHAS, NUM_PROFUNDIDADE, NUM_ARVORES\n",
    "):\n",
    "    modelo_rf = RandomForestRegressor(\n",
    "        n_estimators=n_arvores,\n",
    "        max_leaf_nodes=n_folhas,\n",
    "        max_depth=n_profundidade,\n",
    "        random_state=SEMENTE_ALEATORIA,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "\n",
    "    modelo_rf.fit(X_treino, y_treino)\n",
    "\n",
    "    y_verdadeiro = y_teste\n",
    "    y_previsao = modelo_rf.predict(X_teste)\n",
    "    RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "\n",
    "    print(\n",
    "        f\"O RMSE do modelo RF usando \"\n",
    "        f\"n_estimators={n_arvores} max_leaf_nodes={n_folhas} \"\n",
    "        f\"e max_depth={n_profundidade} foi de {RMSE:.2f} d√≥lares.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notou algum padr√£o?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medindo a import√¢ncia das features usando o conceito de impureza\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nem todas as features t√™m a mesma &ldquo;import√¢ncia&rdquo; quando um modelo realiza uma previs√£o. Em outras palavras, nem todas as features contribuem de maneira igual quando o modelo usa elas para prever o target.\n",
    "\n",
    "A import√¢ncia de uma certa feature em um modelo treinado pelo algoritmo de floresta aleat√≥ria pode ser estimada observando o quanto esta feature contribuiu para reduzir a impureza de cada √°rvore contida no comit√™ (*ensemble*).\n",
    "\n",
    "<u>Impureza</u> √© um conceito importante em √°rvores de decis√£o pois √© usado em diversos algoritmos que nos permitem induzir √°rvores de decis√£o sem a necessidade de testar todas as possibilidades poss√≠veis (lembre-se que induzir *a melhor* √°rvore de decis√£o √© um problema NP-dif√≠cil, logo n√£o sabemos se existe ou n√£o um algoritmo eficiente para resolver este problema).\n",
    "\n",
    "Uma forma intuitiva de se entender impureza no contexto de regress√£o √© pensar que cada target do seu dataset representa uma cor. Quanto mais pr√≥ximos os valores, mais pr√≥ximas as cores. Se todos os exemplos do seu dataset tem a cor roxa, ent√£o seu dataset tem pouca impureza. Se seus exemplos tem todas as cores do espectro vis√≠vel, ent√£o seu dataset tem alta impureza. Em uma √°rvore de decis√£o, a fun√ß√£o de cada v√©rtice que cont√©m um condicional √© separar os dados de forma que cada v√©rtice subsequente tenha uma impureza menor. √â como se os v√©rtices fossem sucessivamente separando as cores em verdes, vermelhos, azuis, etc, durante o caminhar pelo grafo da √°rvore de decis√£o. Cada separa√ß√£o √© feita por um condicional e cada condicional testa uma feature. Logo, √© esperado que algumas features ir√£o reduzir mais a impureza do que outras. Dizemos que as features que reduzem mais a impureza s√£o as que t√™m maior <u>import√¢ncia</u>. Como uma floresta aleat√≥ria √© formada de diversas √°rvores de decis√£o, podemos avaliar com boa estat√≠stica quais s√£o as features que contribuem mais para reduzir a impureza.\n",
    "\n",
    "Vamos ver como podemos usar o `scikit-learn` para fazer essa an√°lise. Primeiramente temos que treinar o modelo. Aqui vamos usar um modelo mais simples com apenas 50 √°rvores para o processo ficar mais r√°pido.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=50, n_jobs=4, random_state=61455)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50, n_jobs=4, random_state=61455)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=50, n_jobs=4, random_state=61455)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_ARVORES = 50\n",
    "N_JOBS = 4\n",
    "\n",
    "modelo_rf = RandomForestRegressor(\n",
    "    n_estimators=N_ARVORES,\n",
    "    random_state=SEMENTE_ALEATORIA,\n",
    "    n_jobs=N_JOBS,\n",
    ")\n",
    "\n",
    "modelo_rf.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `scikit-learn` j√° computa as import√¢ncias de florestas aleat√≥rias automaticamente e armazena elas no atributo `feature_importances_`. Dica: atributos que terminam com um sublinhado (`_`) dizem respeito a caracter√≠sticas do modelo que foram obtidas *ap√≥s* o treinamento. Atributos que n√£o terminam com sublinhado s√£o caracter√≠sticas que foram determinadas *antes* do treinamento.\n",
    "\n",
    "O c√≥digo abaixo avalia a import√¢ncia e seu desvio padr√£o.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "importancia = modelo_rf.feature_importances_\n",
    "desvio_padrao = np.std(\n",
    "    [arvore.feature_importances_ for arvore in modelo_rf.estimators_], axis=0\n",
    ")\n",
    "\n",
    "serie_importancia = pd.Series(importancia, index=FEATURES)\n",
    "\n",
    "fig, axe = plt.subplots()\n",
    "serie_importancia.plot.bar(yerr=desvio_padrao, ax=axe)\n",
    "axe.set_ylabel(\"Redu√ß√£o m√©dia da impureza\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que o peso quilate (`carat`) e a altura (`y`) do diamante s√£o as caracter√≠sticas consideradas mais importantes nesta an√°lise. O peso quilate promoveu uma redu√ß√£o m√©dia da impureza de aproximadamente 0,6 com um desvio padr√£o de aproximadamente 0,2. Fora essas duas, as demais features n√£o apresentaram uma import√¢ncia relevante nesta an√°lise.\n",
    "\n",
    "Note que este par√¢metro que chamamos de import√¢ncia foi obtido utilizando caracter√≠sticas do modelo que ele adquiriu durante seu treino. Logo, este valor de import√¢ncia apenas nos diz quais s√£o as features mais importantes observadas nos dados de treino. Esta import√¢ncia n√£o nos diz quais s√£o as features mais importantes no contexto de generaliza√ß√£o do modelo (isto √©, quais as features mais importantes no ato de prever um dado novo ainda n√£o visto)!\n",
    "\n",
    "Por fim, valores de import√¢ncia estimados pela impureza favorecem features de alta cardinalidade (tipicamente features num√©ricas ou cont√≠nuas) em detrimento de features de baixa cardinalidade (features categ√≥ricas ou features bin√°rias).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medindo a import√¢ncia das features usando a t√©cnica de permuta√ß√£o de atributos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem outras formas de se medir o quanto uma feature √© importante para um modelo. Uma delas √© a t√©cnica de <u>permuta√ß√£o de atributos</u>. Esta t√©cnica se baseia em comparar como uma certa m√©trica de avalia√ß√£o varia se n√≥s embaralharmos os valores de um certo atributo.\n",
    "\n",
    "Vamos imaginar que o valor do peso quilate √© muito importante para definir o pre√ßo do diamante. Se este valor √© de fato muito importante, ent√£o ao embaralharmos os valores desta coluna (isto √©, alterar os valores de posi√ß√£o de forma aleat√≥ria) isso vai impactar *muito* a previs√£o do modelo, fazendo com que ele apresente uma baixa performance nas m√©tricas de avalia√ß√£o.\n",
    "\n",
    "Nesta mesma linha, se embaralharmos os valores de uma feature que n√£o √© importante para a previs√£o do nosso target, ent√£o isso pouco ir√° influenciar a performance do modelo e pouco ir√° afetar as m√©tricas de avalia√ß√£o.\n",
    "\n",
    "Embaralhando todas as features um certo n√∫mero de vezes, n√≥s podemos quantificar o impacto das features nas m√©tricas e com isso temos uma medida da import√¢ncia das features: quanto maior o impacto mais importante a feature √©!\n",
    "\n",
    "Aqui vamos trocar a m√©trica para o coeficiente de determina√ß√£o ($R^2$) ao inv√©s do RMSE. O coeficiente de determina√ß√£o tem diversas formas de se calcular. O calculo que o `scikit-learn` faz considera que um valor de $R^2$ igual a zero significa que o seu modelo √© t√£o bom quanto o modelo baseline que chuta sempre a m√©dia. Para o `scikit-learn` √© poss√≠vel ter um valor de $R^2$ negativo, basta seu modelo ser pior que o modelo baseline.\n",
    "\n",
    "Sem entrar no formalismo estat√≠stico, temos que a forma de calcular o $R^2$ do `scikit-learn` √© v√°lida quando seu modelo linear possu√≠ coeficiente linear (ou seja, tem a forma $y = ax + b$). Neste caso, a equa√ß√£o para o c√°lculo √© $R^2 = 1 - (\\sum_i (y_i - \\hat{y}_i )^2)/(\\sum_i (y_i - \\bar{y})^2)$, onde $\\hat{y}_i$ √© o valor de $y_i$ predito pelo modelo e $\\bar{y} = (1/n) \\sum_{i=1}^{n} y_i$ √© a m√©dia dos valores de $y$.\n",
    "\n",
    "Quando n√≥s usamos m√©tricas para quantificar a performance de modelos de aprendizado de m√°quina, n√≥s buscamos entender como o target previsto se distancia do target verdadeiro. Veja que neste caso n√£o faz sentido termos um coeficiente linear! A rela√ß√£o esperada entre target previsto e target verdadeiro √© uma reta que deve passar pela origem. Neste caso, temos que a f√≥rmula para computar o $R^2$ √© diferente: $R^2 = 1 - (\\sum_i (y_i - \\hat{y}_i )^2)/(\\sum_i y_i^2)$.\n",
    "\n",
    "Colocamos tudo que vimos acima no c√≥digo abaixo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O R^2 da previs√£o √© de 0.9907766431356714\n",
      "\n",
      "carat   0.555 +/- 0.003\n",
      "y       0.182 +/- 0.001\n",
      "x       0.051 +/- 0.000\n",
      "z       0.036 +/- 0.000\n",
      "table   0.032 +/- 0.000\n",
      "depth   0.031 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "N_REPETICOES = 10\n",
    "\n",
    "\n",
    "def R2_1param(modelo, x, y):\n",
    "    \"\"\"Computa o coef. de determina√ß√£o quando hip. alt. n√£o tem coef. linear.\"\"\"\n",
    "    y_pred = modelo.predict(x).ravel()\n",
    "    y_true = (np.array(y)).ravel()\n",
    "    return 1 - sum((y_true - y_pred) ** 2) / sum(y_true**2)\n",
    "\n",
    "\n",
    "X_local = X_treino\n",
    "y_local = y_treino\n",
    "\n",
    "R2 = R2_1param(modelo_rf, X_local, y_local)\n",
    "print(f\"O R^2 da previs√£o √© de {R2}\")\n",
    "\n",
    "# Aqui que calculamos a import√¢ncia das features\n",
    "r = permutation_importance(\n",
    "    modelo_rf,\n",
    "    X_local,\n",
    "    y_local,\n",
    "    n_repeats=N_REPETICOES,\n",
    "    random_state=SEMENTE_ALEATORIA,\n",
    "    scoring=R2_1param,\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "# Aqui n√≥s exibimos os resultados obtidos\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{FEATURES[i]:<8}\"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos da an√°lise acima que o peso quilate por essa an√°lise contribui com grande parte do valor do $R^2$, seguido da feature que representa a altura do diamante.\n",
    "\n",
    "Note que na an√°lise acima n√≥s usamos os dados de treino para computar a import√¢ncia das features. Fizemos isso para poder comparar com as import√¢ncia usando a metodologia da impureza que vimos na se√ß√£o anterior. Podemos rodar o c√≥digo acima usando os dados de teste. Neste caso, estamos avaliando qual das features √© a mais importante para a *generaliza√ß√£o* do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O R^2 da previs√£o √© de 0.9387281285351374\n",
      "\n",
      "carat   0.515 +/- 0.007\n",
      "y       0.135 +/- 0.004\n",
      "x       0.019 +/- 0.001\n",
      "table   0.005 +/- 0.001\n",
      "z       0.005 +/- 0.000\n",
      "depth   0.005 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "X_local = X_teste\n",
    "y_local = y_teste\n",
    "\n",
    "R2 = R2_1param(modelo_rf, X_local, y_local)\n",
    "print(f\"O R^2 da previs√£o √© de {R2}\")\n",
    "\n",
    "# Aqui que calculamos a import√¢ncia das features\n",
    "r = permutation_importance(\n",
    "    modelo_rf,\n",
    "    X_local,\n",
    "    y_local,\n",
    "    n_repeats=N_REPETICOES,\n",
    "    random_state=SEMENTE_ALEATORIA,\n",
    "    scoring=R2_1param,\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "# Aqui n√≥s exibimos os resultados obtidos\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{FEATURES[i]:<8}\"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√£o observamos uma diferen√ßa significativa entre o resultado utilizando os dados de teste em compara√ß√£o com os de treino.\n",
    "\n",
    "Features que tem grande import√¢ncia nos dados de treino mas n√£o tem grande import√¢ncia nos dados de teste podem ser features que levam ao sobreajuste.\n",
    "\n",
    "Por fim, √© importante ressaltar que se seu modelo <u>√© ruim</u> ent√£o sua an√°lise de import√¢ncia n√£o ser√° representativa do que realmente importa. A an√°lise de import√¢ncia √© indissoci√°vel do modelo usado para infer√™ncia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refer√™ncias e leitura adicional\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "2.  [https://youtu.be/J4Wdy0Wc_xQ](https://youtu.be/J4Wdy0Wc_xQ)\n",
    "3.  [https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html)\n",
    "4.  [https://scikit-learn.org/stable/modules/permutation_importance.html](https://scikit-learn.org/stable/modules/permutation_importance.html)\n",
    "5.  [https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance)\n",
    "6.  [https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py](https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py)\n",
    "7.  [https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py](https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py)\n",
    "8.  [https://stats.stackexchange.com/a/360750](https://stats.stackexchange.com/a/360750)\n",
    "9.  [https://stats.stackexchange.com/a/37442](https://stats.stackexchange.com/a/37442)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
