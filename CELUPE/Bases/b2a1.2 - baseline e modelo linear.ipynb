{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline e modelo linear\n",
    "========================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar nosso primeiro modelo de machine learning! Este √© um dos modelos mais simples que existe: a sua estrat√©gia √© sempre prever a m√©dia dos valores do target.\n",
    "\n",
    "Vamos primeiro carregar os dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 61455\n",
    "DATASET_NAME = \"diamonds\"\n",
    "FEATURES = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "TARGET = [\"price\"]\n",
    "\n",
    "df = sns.load_dataset(DATASET_NAME)\n",
    "\n",
    "indices = df.index\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size=TAMANHO_TESTE, random_state=SEMENTE_ALEATORIA\n",
    ")\n",
    "\n",
    "df_treino = df.loc[indices_treino]\n",
    "df_teste = df.loc[indices_teste]\n",
    "\n",
    "# observe que usamos o .values aqui pois queremos apenas os valores\n",
    "X_treino = df_treino.reindex(FEATURES, axis=1).values\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values\n",
    "X_teste = df_teste.reindex(FEATURES, axis=1).values\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos treinar nosso modelo!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3932.63554155 3932.63554155 3932.63554155 ... 3932.63554155 3932.63554155\n",
      " 3932.63554155]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# cria o modelo\n",
    "modelo_baseline = DummyRegressor()\n",
    "\n",
    "# treina o modelo\n",
    "modelo_baseline.fit(X_treino, y_treino)\n",
    "\n",
    "# realiza uma previs√£o usando o modelo treinado\n",
    "previsao = modelo_baseline.predict(X_teste)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como saber se nosso modelo √© bom? Para isso precisamos de *m√©tricas*! Uma m√©trica bastante √∫til √© a raiz quadrada do erro quadr√°tico m√©dio (RMSE, *root mean squared error*).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo baseline foi de 3984.6429215453436 d√≥lares.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_verdadeiro = y_teste\n",
    "y_previsao = modelo_baseline.predict(X_teste)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "\n",
    "print(f\"O RMSE do modelo baseline foi de {RMSE} d√≥lares.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voc√™ deve estar se perguntando porque um modelo t√£o simples como este existe. A resposta √© que este √© o tipo de modelo que usamos como *baseline*. Quando estudamos aprendizado de m√°quina n√≥s geralmente queremos *comparar* diferentes modelos em busca do que tem a melhor performance. Para isso, √© necess√°rio ter mais de um modelo dispon√≠vel (do contr√°rio n√£o conseguimos comparar nada).\n",
    "\n",
    "Os modelos *dummy* (tamb√©m conhecidos como modelos fict√≠cios) servem como uma primeira linha de base para nossas compara√ß√µes. Agora que temos esse modelo, sabemos que qualquer modelo que tiver performance melhor que este ser√° bem-vindo. Tamb√©m sabemos que se algum modelo tiver performance pior que este modelo, ent√£o ele √© t√£o ruim a ponto de ser pior que apenas chutar a m√©dia&#x2026;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo linear\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK&#x2026; quem sabe voc√™ n√£o tenha ficado t√£o animado assim com seu primeiro modelo de machine learning, mas considere ele o &ldquo;Ol√°, mundo!&rdquo; do aprendizado de m√°quina. Este tipo de modelo que vimos j√° nos mostrou muita coisa interessante sobre como o `scikit-learn` funciona! E a boa not√≠cia √© que esse conhecimento pode ser usado para os modelos mais interessantes!\n",
    "\n",
    "Vamos treinar um outro modelo considerado simples, um modelo linear! Este modelo, assim como o nome sugere, ir√° buscar como relacionar linearmente as suas features com seu target. Apesar de nem tudo nessa vida ser linear, modelos lineares podem ser muito √∫teis em diversas situa√ß√µes e eles trazem a vantagem que s√£o modelos que podem ser facilmente *analisados* (isto √©, voc√™ pode facilmente se debru√ßar sobre o modelo e analisar como ele faz as suas previs√µes).\n",
    "\n",
    "Novamente, vamos carregar os dados (aqui √© a mesma c√©lula de cima, est√° repetida apenas para facilitar a visualiza√ß√£o).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 61455\n",
    "DATASET_NAME = \"diamonds\"\n",
    "FEATURES = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "TARGET = [\"price\"]\n",
    "\n",
    "df = sns.load_dataset(DATASET_NAME)\n",
    "\n",
    "indices = df.index\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size=TAMANHO_TESTE, random_state=SEMENTE_ALEATORIA\n",
    ")\n",
    "\n",
    "df_treino = df.loc[indices_treino]\n",
    "df_teste = df.loc[indices_teste]\n",
    "\n",
    "# observe que usamos o .values aqui pois queremos apenas os valores\n",
    "X_treino = df_treino.reindex(FEATURES, axis=1).values\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values\n",
    "X_teste = df_teste.reindex(FEATURES, axis=1).values\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hora de treinar nosso modelo! Observe que a sintaxe √© praticamente a mesma que usamos acima!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 897.93104962]\n",
      " [ 116.55100153]\n",
      " [ 722.52416738]\n",
      " ...\n",
      " [ 490.07633889]\n",
      " [1018.33532029]\n",
      " [ 706.0257798 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# cria o modelo\n",
    "modelo_linear = LinearRegression()\n",
    "\n",
    "# treina o modelo\n",
    "modelo_linear.fit(X_treino, y_treino)\n",
    "\n",
    "# realiza uma previs√£o usando o modelo treinado\n",
    "previsao = modelo_linear.predict(X_teste)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos checar se nosso modelo linear tem performance melhor que o modelo baseline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo linear foi de 1476.6783402952751 d√≥lares.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_verdadeiro = y_teste\n",
    "y_previsao = modelo_linear.predict(X_teste)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "\n",
    "print(f\"O RMSE do modelo linear foi de {RMSE} d√≥lares.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O RMSE do modelo linear foi de 1477 d√≥lares enquanto que a performance do modelo baseline foi de 3985 d√≥lares. Estamos indo na dire√ß√£o certa! üéâ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando os dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em certos casos √© ben√©fico ou at√© necess√°rio normalizar os dados antes de treinar seu modelo. Vamos ver como fazer isso usando o `scikit-learn`. Iniciamos carregando os dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 61455\n",
    "DATASET_NAME = \"diamonds\"\n",
    "FEATURES = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "TARGET = [\"price\"]\n",
    "\n",
    "df = sns.load_dataset(DATASET_NAME)\n",
    "\n",
    "indices = df.index\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size=TAMANHO_TESTE, random_state=SEMENTE_ALEATORIA\n",
    ")\n",
    "\n",
    "df_treino = df.loc[indices_treino]\n",
    "df_teste = df.loc[indices_teste]\n",
    "\n",
    "# observe que usamos o .values aqui pois queremos apenas os valores\n",
    "X_treino = df_treino.reindex(FEATURES, axis=1).values\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values\n",
    "X_teste = df_teste.reindex(FEATURES, axis=1).values\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `scikit-learn` j√° tem embutido diversas fun√ß√µes para normalizar os dados. Vamos usar a normaliza√ß√£o pelo m√≠nimo e m√°ximo (fun√ß√£o `MinMaxScaler`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizador_x = MinMaxScaler()\n",
    "normalizador_y = MinMaxScaler()\n",
    "\n",
    "normalizador_x.fit(X_treino)\n",
    "normalizador_y.fit(y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe na c√©lula acima que n√≥s fitamos o normalizador apenas nos dados de treino. Lembre-se que os dados de teste n√£o podem ser usados durante o treino diretamente <u>ou indiretamente</u>! Voc√™ deve sempre considerar que os dados de teste <u>n√£o existem</u>! Se voc√™ falhar em seguir essa regra, ir√° cometer um dos 7 pecados capitais do aprendizado de m√°quina, o pecado do [vazamento de dados](https://en.wikipedia.org/wiki/Leakage_(machine_learning)).\n",
    "\n",
    "Agora vamos ajustar nosso modelo. Veja que usamos o normalizador para transformar (`transform`) e reverter (`inverse_transform`) os valores das features e do target.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1459.91052178]\n",
      " [1671.38453724]\n",
      " [1265.63384206]\n",
      " ...\n",
      " [3499.6381101 ]\n",
      " [ 233.55501214]\n",
      " [ 671.81326587]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# cria o modelo\n",
    "modelo_linear = LinearRegression()\n",
    "\n",
    "# treina o modelo\n",
    "modelo_linear.fit(\n",
    "    normalizador_x.transform(X_treino),\n",
    "    normalizador_y.transform(y_treino),\n",
    ")\n",
    "\n",
    "# realiza uma previs√£o usando o modelo treinado\n",
    "previsao = modelo_linear.predict(normalizador_x.transform(X_treino))\n",
    "previsao = normalizador_y.inverse_transform(previsao)\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, vamos investigar se a normaliza√ß√£o melhorou a performance do nosso modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo linear foi de 1476.6783402952751 d√≥lares.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_verdadeiro = y_teste\n",
    "y_previsao = modelo_linear.predict(normalizador_x.transform(X_teste))\n",
    "y_previsao = normalizador_y.inverse_transform(y_previsao)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False)\n",
    "\n",
    "print(f\"O RMSE do modelo linear foi de {RMSE} d√≥lares.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como voc√™ pode ver, o RMSE do modelo linear sem normaliza√ß√£o foi de 1477 d√≥lares e o RMSE do modelo linear com normaliza√ß√£o foi de 1477 d√≥lares. Isso nos mostra que neste caso, n√£o houve diferen√ßa em se aplicar a normaliza√ß√£o nos dados.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
