{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36532927-9c5f-4f7e-b40a-b22f748b6c2d",
   "metadata": {},
   "source": [
    "### Modelo Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe3f6b-d87a-4ce2-8f55-a8ecc8161d2c",
   "metadata": {},
   "source": [
    "É um modelo simples usado como referência para comparar o desempenho do modelo real que está sendo construído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069411aa-986d-48c2-9322-bb53ccf2a8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Mohs Hardness  Specific Gravity  Refractive Index  Molar Mass  \\\n",
      "0             4.50             3.240             1.580  817.339002   \n",
      "1             2.75             3.446             1.592  435.069330   \n",
      "2             2.00             4.420             2.085  921.092220   \n",
      "4             5.50             1.050             1.634  861.185368   \n",
      "5             3.50             3.295             1.457  225.618151   \n",
      "..             ...               ...               ...         ...   \n",
      "803           7.50             4.650             1.928  526.041800   \n",
      "805           6.50             3.230             1.702  379.378178   \n",
      "806           3.50             2.180             1.590  492.887716   \n",
      "807           7.00             3.411             1.596  263.580584   \n",
      "808           0.00             3.146             1.633  576.801907   \n",
      "\n",
      "     Molar Volume  Calculated Density  \n",
      "0        0.123390               5.498  \n",
      "1        0.056083               6.439  \n",
      "2        0.122631               6.234  \n",
      "4        0.112074               6.378  \n",
      "5        0.044887               4.172  \n",
      "..            ...                 ...  \n",
      "803      0.078468               5.564  \n",
      "805      0.100890               3.121  \n",
      "806      0.078566               5.207  \n",
      "807      0.089458               2.446  \n",
      "808      0.078605               6.091  \n",
      "\n",
      "[588 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importação das bibliotecas e funções\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyRegressor # Importa o DummyRegressor que é um tipo de regressor para previsão com base em estratégias simples\n",
    "\n",
    "\n",
    "#criando o DataFrame \"df_chem\"\n",
    "df = pd.read_csv(\"Minerals_Database3.csv\")  # Importação do dataset para ser utilizado como dataframe\n",
    "# Remoção de colunas não necessárias para o dataframe\n",
    "\n",
    "df = df.drop(['A'], axis=1)\n",
    "df = df.drop(['Name'], axis=1)\n",
    "\n",
    "dados_cat = df.reindex(df.columns[[0,2,4]], axis = 1) # Remoção de dados categóricos\n",
    "dados_categoricos = dados_cat.astype(\"category\") # Tratamento de dados para o tipo categórico\n",
    "newlist = [x for x in range(7,135)] # Range para pegarmos dados que estão em porcentagem\n",
    "porcent_df = df.reindex(df.columns[newlist], axis = 1) # Coleta dos dados de elementos em porcentagem\n",
    "df_chem = df.reindex(df.columns[[1,3,5,135,136,137]], axis=1) # Reindexação de um dataframe contendo apenas propriedades fisico-químicas\n",
    "df_chem\n",
    "df_chem, dados_categoricos\n",
    "\n",
    "df_remove=df_chem.loc[(df_chem[\"Refractive Index\"] == 0.000)] #remove as linhas (objetos), cujo valor do índice de refração é 0\n",
    "\n",
    "df_chem = df_chem.drop(df_remove.index) #considera que o dataframe df_chem é o dataframe com as linhas removidas\n",
    "print(df_chem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4efc1d-df28-4ab9-a440-e178dd534ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Mohs Hardness  Specific Gravity  Refractive Index   Molar Mass  \\\n",
      "615           0.00             5.700             1.737   298.038100   \n",
      "194           5.50             4.650             2.120   123.842500   \n",
      "306           4.50             2.285             1.516   257.230046   \n",
      "82            0.00             4.380             1.793   426.292200   \n",
      "339           3.00             6.420             2.358  1560.452603   \n",
      "..             ...               ...               ...          ...   \n",
      "64            2.50             1.715             1.513   155.071500   \n",
      "29            6.25             2.625             1.535   411.331124   \n",
      "762           5.50             0.000             1.495   340.284075   \n",
      "367           1.00             3.197             1.641   490.595370   \n",
      "250           5.00             4.535             2.069   656.503600   \n",
      "\n",
      "     Molar Volume  Calculated Density  \n",
      "615      0.033606               7.361  \n",
      "194      0.011210               9.169  \n",
      "306      0.033718               6.332  \n",
      "82       0.067053               5.277  \n",
      "339      0.190472               6.800  \n",
      "..            ...                 ...  \n",
      "64       0.033455               3.847  \n",
      "29       0.089706               3.806  \n",
      "762      0.089726               3.148  \n",
      "367      0.044914               9.066  \n",
      "250      0.100857               5.403  \n",
      "\n",
      "[441 rows x 6 columns]\n",
      "\n",
      "     Mohs Hardness  Specific Gravity  Refractive Index   Molar Mass  \\\n",
      "470           4.25             3.660             1.690   277.129780   \n",
      "611           2.50             2.290             1.536   223.971720   \n",
      "252           5.00             3.070             1.651   250.753231   \n",
      "716           6.00             2.820             1.627   746.816808   \n",
      "532           3.00             2.305             1.525  1095.418700   \n",
      "..             ...               ...               ...          ...   \n",
      "424           3.25             6.241             2.117   258.652100   \n",
      "388           5.50             3.240             1.711   925.116139   \n",
      "283           4.00             3.306             1.441    59.076403   \n",
      "454           3.75             2.270             1.524   613.908400   \n",
      "200           5.50             3.305             1.666   215.566380   \n",
      "\n",
      "     Molar Volume  Calculated Density  \n",
      "470      0.033683               6.829  \n",
      "611      0.179271               1.037  \n",
      "252      0.078441               2.653  \n",
      "716      0.235392               2.633  \n",
      "532      0.258006               3.524  \n",
      "..            ...                 ...  \n",
      "424      0.022244               9.651  \n",
      "388      0.123484               6.218  \n",
      "283      0.011228               4.367  \n",
      "454      0.123403               4.129  \n",
      "200      0.078447               2.281  \n",
      "\n",
      "[147 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "tamanho = 0.25 # Fração de dados escolhida para treino e teste\n",
    "seed = 567 # Determina o ponto onde será feita a separação dos dados\n",
    "\n",
    "i = df_chem.index # encontra a posição do índice de um elemento na lista de dados\n",
    "i_treino, i_teste = train_test_split(i, test_size=tamanho, random_state = seed) #Split entre dados treino e teste\n",
    "\n",
    "#Definindo o acesso ao grupo de linhas que serão usandos para treino e teste\n",
    "df_treino = df_chem.loc[i_treino]\n",
    "df_teste = df_chem.loc[i_teste]\n",
    "\n",
    "print(df_treino)\n",
    "print()\n",
    "print(df_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef692157-58ab-48d0-a1a1-99aa857e93f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split arrays or matrices into random train and test subsets\n",
      "\n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "\n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "\n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "\n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "\n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "\n",
      "\n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "\n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "        Read more in the :ref:`User Guide <stratification>`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "\n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "\n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "\n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(train_test_split.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0a0d11-adbf-479f-999b-3b696d1d10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo preditivo\n",
    "# Definições de atributos e targets\n",
    "nome = 'df_chem'\n",
    "atributos = [\"Specific Gravity\", \"Mohs Hardness\", 'Molar Mass', 'Molar Volume', 'Calculated Density']\n",
    "target = [\"Refractive Index\"]\n",
    "\n",
    "X_treino = df_treino.reindex(atributos, axis=1).values\n",
    "y_treino = df_treino.reindex(target, axis=1).values\n",
    "X_teste = df_teste.reindex(atributos, axis=1).values\n",
    "y_teste = df_teste.reindex(target, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef83b13-975f-4c8f-b578-7361ec38444b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542 1.71321542\n",
      " 1.71321542 1.71321542 1.71321542]\n"
     ]
    }
   ],
   "source": [
    "# Teste modelo Baseline\n",
    "modelo_baseline = DummyRegressor()# Criação do Modelo fictício\n",
    "\n",
    "modelo_baseline.fit(X_treino, y_treino) # Treino do Modelo fictício\n",
    "\n",
    "previsao = modelo_baseline.predict(X_teste) # Previsão do modelo a partir do treino\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36dcf6aa-b595-4f7c-8146-2895c8f8f831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    DummyRegressor is a regressor that makes predictions using\n",
      "    simple rules.\n",
      "\n",
      "    This regressor is useful as a simple baseline to compare with other\n",
      "    (real) regressors. Do not use it for real problems.\n",
      "\n",
      "    Read more in the :ref:`User Guide <dummy_estimators>`.\n",
      "\n",
      "    .. versionadded:: 0.13\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    strategy : {\"mean\", \"median\", \"quantile\", \"constant\"}, default=\"mean\"\n",
      "        Strategy to use to generate predictions.\n",
      "\n",
      "        * \"mean\": always predicts the mean of the training set\n",
      "        * \"median\": always predicts the median of the training set\n",
      "        * \"quantile\": always predicts a specified quantile of the training set,\n",
      "          provided with the quantile parameter.\n",
      "        * \"constant\": always predicts a constant value that is provided by\n",
      "          the user.\n",
      "\n",
      "    constant : int or float or array-like of shape (n_outputs,), default=None\n",
      "        The explicit constant as predicted by the \"constant\" strategy. This\n",
      "        parameter is useful only for the \"constant\" strategy.\n",
      "\n",
      "    quantile : float in [0.0, 1.0], default=None\n",
      "        The quantile to predict using the \"quantile\" strategy. A quantile of\n",
      "        0.5 corresponds to the median, while 0.0 to the minimum and 1.0 to the\n",
      "        maximum.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    constant_ : ndarray of shape (1, n_outputs)\n",
      "        Mean or median or quantile of the training targets or constant value\n",
      "        given by the user.\n",
      "\n",
      "    n_outputs_ : int\n",
      "        Number of outputs.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.dummy import DummyRegressor\n",
      "    >>> X = np.array([1.0, 2.0, 3.0, 4.0])\n",
      "    >>> y = np.array([2.0, 3.0, 5.0, 10.0])\n",
      "    >>> dummy_regr = DummyRegressor(strategy=\"mean\")\n",
      "    >>> dummy_regr.fit(X, y)\n",
      "    DummyRegressor()\n",
      "    >>> dummy_regr.predict(X)\n",
      "    array([5., 5., 5., 5.])\n",
      "    >>> dummy_regr.score(X, y)\n",
      "    0.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(DummyRegressor.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7092bd-cde1-454a-b463-d5dcc8f6f9d6",
   "metadata": {},
   "source": [
    "## Resultado do modelo baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea6de26-e217-47c2-b53a-46e367f839e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A RMSE do modelo de baseline foi uma Indice Refrativo de 0.2560250291075808\n"
     ]
    }
   ],
   "source": [
    "y_verdadeiro = y_teste\n",
    "y_previsao = modelo_baseline.predict(X_teste)\n",
    "\n",
    "RMSE = mean_squared_error(y_verdadeiro, y_previsao, squared=False) # Método da raiz quadrada do erro quadrático médio\n",
    "print(f'A RMSE do modelo de baseline foi uma Indice Refrativo de {RMSE}')\n",
    "#print(y_verdadeiro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c6e94a-a7b6-4774-9e87-7a359259ee8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error regression loss.\n",
      "\n",
      "    Read more in the :ref:`User Guide <mean_squared_error>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "        Ground truth (correct) target values.\n",
      "\n",
      "    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "        Estimated target values.\n",
      "\n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "\n",
      "    multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "        Defines aggregating of multiple output values.\n",
      "        Array-like value defines weights used to average errors.\n",
      "\n",
      "        'raw_values' :\n",
      "            Returns a full set of errors in case of multioutput input.\n",
      "\n",
      "        'uniform_average' :\n",
      "            Errors of all outputs are averaged with uniform weight.\n",
      "\n",
      "    squared : bool, default=True\n",
      "        If True returns MSE value, if False returns RMSE value.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    loss : float or ndarray of floats\n",
      "        A non-negative floating point value (the best value is 0.0), or an\n",
      "        array of floating point values, one for each individual target.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import mean_squared_error\n",
      "    >>> y_true = [3, -0.5, 2, 7]\n",
      "    >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "    >>> mean_squared_error(y_true, y_pred)\n",
      "    0.375\n",
      "    >>> y_true = [3, -0.5, 2, 7]\n",
      "    >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "    >>> mean_squared_error(y_true, y_pred, squared=False)\n",
      "    0.612...\n",
      "    >>> y_true = [[0.5, 1],[-1, 1],[7, -6]]\n",
      "    >>> y_pred = [[0, 2],[-1, 2],[8, -5]]\n",
      "    >>> mean_squared_error(y_true, y_pred)\n",
      "    0.708...\n",
      "    >>> mean_squared_error(y_true, y_pred, squared=False)\n",
      "    0.822...\n",
      "    >>> mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
      "    array([0.41666667, 1.        ])\n",
      "    >>> mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
      "    0.825...\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error.__doc__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
