{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valida√ß√£o cruzada\n",
    "=================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O problema do vazamento de dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos pensar em uma situa√ß√£o hipot√©tica: voc√™ tem um certo conjunto de dados (features + target) e quer treinar uma √°rvore de decis√£o usando estes dados. Voc√™ se recorda que √© necess√°rio dividir seu conjunto de dados em treino e teste e faz exatamente isso antes de seguir em frente (usando uma semente aleat√≥ria para que sua divis√£o seja reprodut√≠vel). Na hora de treinar seu modelo, voc√™ decide utilizar os hiperpar√¢metros padr√£o do `scikit-learn`, por√©m usa uma semente aleat√≥ria pois tem interesse em reproduzir seus resultados. Voc√™ segue ent√£o com o ajuste do seu modelo usando os dados de treino e em seguida decide ver como seu modelo se comporta com dados novos ao tentar prever os dados de teste que n√£o foram &ldquo;vistos&rdquo; durante o treino.\n",
    "\n",
    "Esse √© um cen√°rio que j√° foi explorado neste curso, nada de novo at√© agora.\n",
    "\n",
    "Digamos que voc√™ est√° curiosa e retorna e altere a semente aleat√≥ria para um outro valor, repetindo todo o processo de split, treino e teste com a nova semente. Como voc√™ alterou a semente aleat√≥ria, outros dados ser√£o selecionados no split de treino e teste e outra √°rvore de decis√£o ser√° induzida durante o treino do modelo. Logo, a performance do modelo no conjunto de teste muito provavelmente ser√° diferente, podendo ser melhor ou pior.\n",
    "\n",
    "At√© aqui nada surpreendente.\n",
    "\n",
    "Agora imagina que voc√™ cria um la√ßo de repeti√ß√£o que testa 1000000 valores de semente aleat√≥ria diferentes para realizar o mesmo processo de split, treino e teste descrito acima. Para cada semente testada, voc√™ armazena o valor da semente e a performance do modelo (o valor de RMSE, por exemplo). O que voc√™ espera que aconte√ßa?\n",
    "\n",
    "O resultado √© que, por puro acaso, alguns modelos ir√£o apresentar m√©tricas melhores que outros. A pergunta √©: <u>seria uma boa ideia selecionar o modelo que teve a melhor m√©trica, pois esse √© o modelo que melhor generaliza seu problema</u>?\n",
    "\n",
    "A resposta √© **N√ÉO**. Ao fazer esse exerc√≠cio de selecionar &ldquo;a melhor semente aleat√≥ria&rdquo;, voc√™ est√° permitindo que o acaso fa√ßa sua magia e te engane que voc√™ encontrou um modelo melhor que os outros, quando na verdade voc√™ fez um processo chamado de <u>vazamento de dados</u> (*data leakage* em ingl√™s) que aumentou o sobreajuste do seu modelo e te enganou sobre isso (tudo ao mesmo tempo!).\n",
    "\n",
    "*Data leakage* √© quando a informa√ß√£o do conjunto de teste &ldquo;vaza&rdquo; no seu treino e leva voc√™ a sobreajustar seu modelo sem saber que est√° sobreajustando! Ao selecionar &ldquo;a melhor semente aleat√≥ria&rdquo;, voc√™ est√° usando a informa√ß√£o da m√©trica no conjunto de teste para realizar a escolha do seu modelo, o que faz com que a informa√ß√£o do conjunto de teste seja usada na sele√ß√£o do modelo o que √© um **grande N√ÉO-N√ÉO**.\n",
    "\n",
    "Vamos repetir pois isso √© muito importante: <u>voc√™ n√£o pode usar o conjunto de teste no processo de escolha do modelo</u>. Ali√°s, voc√™ n√£o pode usar o conjunto de teste para nada, a n√£o ser o teste final do eventual modelo selecionado. (Isso quer dizer que tamb√©m n√£o podemos usar os dados de teste para normaliza√ß√µes!)\n",
    "\n",
    "At√© agora, nos notebooks anteriores, n√≥s usamos as m√©tricas do conjunto de teste para *observar* como diferentes modelos se comportam, mas essa **n√£o** pode ser nossa estrat√©gia para selecionar &ldquo;o melhor modelo&rdquo; para nossos dados.\n",
    "\n",
    "Mas&#x2026; se n√£o podemos usar o conjunto de teste e podemos ter o azar de sermos contemplados com uma semente aleat√≥ria que nos leva ao sobreajuste, o que podemos fazer para nos sentirmos mais confiantes nos nossos modelos de machine learning?\n",
    "\n",
    "A resposta, meus caros, √© o m√©todo da **Valida√ß√£o Cruzada**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valida√ß√£o Cruzada\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de ver o que √© a valida√ß√£o cruzada (*cross-validation* em ingl√™s), vamos ver onde que ela entra dentro do fluxograma de aprendizado de m√°quina.\n",
    "\n",
    "![img](https://scikit-learn.org/stable/_images/grid_search_workflow.png)\n",
    "\n",
    "Veja que a valida√ß√£o cruzada √© uma estrat√©gia que usamos para encontrar um conjunto razoavelmente bom de hiperpar√¢metros do modelo (na imagem est√° escrito *best parameters*, mas eu diria que o melhor seria se estivesse escrito *reasonably good hyperparameters*).\n",
    "\n",
    "Existem diversos tipos de valida√ß√£o cruzada, mas todos seguem a mesma ideia geral: os dados de treino n√£o s√£o *todos* utilizados para treinar o modelo, uma fra√ß√£o deles √© reservada para o processo de valida√ß√£o do modelo; esta estrat√©gia √© repetida algumas vezes para termos uma boa estat√≠stica do processo de valida√ß√£o.\n",
    "\n",
    "Vamos ver um tipo de valida√ß√£o cruzada muito utilizado: a valida√ß√£o $k$-fold. Este m√©todo consiste em dividir o conjunto de treino em $k$ conjuntos de dados de tamanho igual (ou o mais pr√≥ximo poss√≠vel disso). O modelo sendo validado ser√° treinado $k$ vezes neste processo, cada treino ser√° realizado com $k-1$ destes conjuntos de dados e a performance do modelo ser√° mensurada no conjunto que ficou de fora (chamado aqui de conjunto de valida√ß√£o). Este processo √© repetido de forma que todos os $k$ conjuntos sejam o conjunto de valida√ß√£o uma (e apenas uma) vez.\n",
    "\n",
    "Abaixo temos uma representa√ß√£o visual da valida√ß√£o $k$-fold para o valor de $k=5$.\n",
    "\n",
    "![img](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
    "\n",
    "Ap√≥s a valida√ß√£o $k$-fold teremos uma lista de tamanho $k$ representando a performance dos $k$ modelos que treinamos. A compara√ß√£o entre diferentes modelos se d√° pela m√©dia da performance.\n",
    "\n",
    "Esta estrat√©gia de valida√ß√£o cruzada nos permite comparar algoritmos diferentes (√°rvores de decis√£o e regress√£o linear, por exemplo) bem como algoritmos iguais com diferentes conjuntos de hiperpar√¢metros (floresta aleat√≥ria com 100 ou 1000 √°rvores de decis√£o, por exemplo).\n",
    "\n",
    "Ap√≥s a compara√ß√£o dos modelos, o que apresentar as melhores m√©tricas dever√° ser escolhido. O pr√≥ximo passo √© ent√£o treinar **o modelo semifinal** usando o algoritmo e conjunto de hiperpar√¢metros escolhidos e *todo* o conjunto de dados de treino. Este **modelo semifinal** √© o √∫nico que ter√° a honra de prever os dados de teste. Os demais n√£o poder√£o ter essa honra para n√£o enviesar a nossa an√°lise e cair novamente no pecado capital do vazamento de dados.\n",
    "\n",
    "Ap√≥s a previs√£o dos dados de teste voc√™ deve se perguntar se seu modelo teve a capacidade de generalizar o problema. Isto √©, a performance nos dados de teste est√° dentro do que voc√™ consideraria aceit√°vel?\n",
    "\n",
    "-   Se sim, ent√£o voc√™ pode finalmente treinar **o modelo final** usando *todos* seus dados (treino + teste); este √© o modelo que voc√™ usar√° caso queira fazer algum tipo de previs√£o futura.\n",
    "\n",
    "-   Se n√£o, ent√£o fim de jogo; voc√™ n√£o conseguiu encontrar um bom modelo usando a metodologia proposta&#x2026; se ainda sim quiser usar aprendizado de m√°quina neste problema dever√° retornar desde o in√≠cio e propor altera√ß√µes na sua metodologia e realizar o processo todo do zero. Quem sabe suas features n√£o s√£o suficientes para descrever o problema. Quem sabe seus algoritmos n√£o s√£o suficientes para capturar a complexidade dos dados. Quem sabe os hiperpar√¢metros escolhidos promoveram subajuste ou sobreajuste. Etc&#x2026;\n",
    "\n",
    "Uma das melhores fontes para se ler sobre valida√ß√£o cruzada √© a pr√≥pria [documenta√ß√£o](https://scikit-learn.org/stable/modules/cross_validation.html) do `scikit-learn`. O processo e diferentes estrat√©gias que temos s√£o muito bem explicadas l√°. Infelizmente, o v√≠deo do StatQuest sobre esse assunto √© simples demais e n√£o discute a quest√£o do conjunto de treino e teste. Confiram tamb√©m [este v√≠deo](https://youtu.be/-8s9KuNo5SA) que explica muito bem a valida√ß√£o cruzada, mostrando os erros comuns no aprendizado de m√°quina.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando valida√ß√£o cruzada para comparar diferentes modelos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar valida√ß√£o cruzada para comparar diferentes modelos para nosso dataset de diamantes. Neste caso, usaremos a valida√ß√£o $k$-fold considerando um valor de $k=10$. Em geral, o valor de $k$ escolhido costuma ser 5 ou 10.\n",
    "\n",
    "Primeiramente precisamos carregar os dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TAMANHO_TESTE = 0.1\n",
    "SEMENTE_ALEATORIA = 61455\n",
    "DATASET_NAME = \"diamonds\"\n",
    "FEATURES = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "TARGET = [\"price\"]\n",
    "\n",
    "df = sns.load_dataset(DATASET_NAME)\n",
    "\n",
    "indices = df.index\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size=TAMANHO_TESTE, random_state=SEMENTE_ALEATORIA\n",
    ")\n",
    "\n",
    "df_treino = df.loc[indices_treino]\n",
    "df_teste = df.loc[indices_teste]\n",
    "\n",
    "X_treino = df_treino.reindex(FEATURES, axis=1).values\n",
    "y_treino = df_treino.reindex(TARGET, axis=1).values.ravel()\n",
    "X_teste = df_teste.reindex(FEATURES, axis=1).values\n",
    "y_teste = df_teste.reindex(TARGET, axis=1).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar a valida√ß√£o $k$-fold usamos a fun√ß√£o `cross_val_score`. Para isso, precisamos criar o modelo antes como mostra o c√≥digo abaixo. Essa fun√ß√£o j√° cuida de tudo para n√≥s! Ela separa os dados em folds, treina o modelo e computa a m√©trica desejada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os scores foram de:  [0.86931393 0.86747536 0.87234042 0.87176931 0.87338384 0.87551236\n",
      " 0.86697302 0.86332081 0.86679812 0.86782233]\n",
      "\n",
      "A m√©dia dos scores √© de:  0.8694709483426829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "NUM_ARVORES = 10\n",
    "NUM_FOLDS = 10\n",
    "NUM_CPU_CORES = 4\n",
    "\n",
    "modelo_rf = RandomForestRegressor(\n",
    "    n_estimators=NUM_ARVORES,\n",
    "    random_state=SEMENTE_ALEATORIA,\n",
    "    n_jobs=NUM_CPU_CORES,\n",
    ")\n",
    "scores = cross_val_score(\n",
    "    modelo_rf,\n",
    "    X_treino,\n",
    "    y_treino,\n",
    "    cv=NUM_FOLDS,\n",
    ")\n",
    "\n",
    "print(\"Os scores foram de: \", scores)\n",
    "print()\n",
    "print(\"A m√©dia dos scores √© de: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando nenhuma m√©trica √© indicada na fun√ß√£o `cross_val_score`, o `scikit-learn` usar√° a m√©trica padr√£o do seu modelo utilizado (costuma ser o $R^2$ para problemas de regress√£o ou a acur√°cia para problemas de classifica√ß√£o). Neste caso, os valores acima indicam o $R^2$ do modelo obtido. Como j√° discutido em outro notebook, a forma como o `scikit-learn` computa o $R^2$ n√£o √© a ideal.\n",
    "\n",
    "Existem diversos scores poss√≠veis que podemos utilizar para a valida√ß√£o cruzada. Voc√™ pode checar as que j√° est√£o embutidas no `scikit-learn` na [documenta√ß√£o](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values). Digamos que voc√™ queira usar o RMSE como score, basta passar a string `\"neg_root_mean_squared_error\"` no argumento `scoring`, assim como feito abaixo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os scores foram de:  [-1402.1516967  -1446.83751054 -1427.34209668 -1422.34538022\n",
      " -1439.66733232 -1391.7646204  -1448.98320846 -1443.18534277\n",
      " -1496.46828125 -1490.92054804]\n",
      "\n",
      "A m√©dia dos scores √© de:  -1440.9666017372572\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    modelo_rf,\n",
    "    X_treino,\n",
    "    y_treino,\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    ")\n",
    "\n",
    "print(\"Os scores foram de: \", scores)\n",
    "print()\n",
    "print(\"A m√©dia dos scores √© de: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U√©, como assim o RMSE deu negativo? O $R^2$ tinha funcionado bem (era positivo, como esperado), mas o RMSE estranhamente deu negativo. Isso acontece porque o `scikit-learn` definiu que m√©tricas com o nome de *score* devem todas seguir a mesma regra: quanto maior, melhor! Sabemos que isso √© v√°lido para o $R^2$, por isso n√£o tivemos surpresas. Por√©m, o RMSE √© o contr√°rio: quanto menor o RMSE melhor a performance do meu modelo. Para satisfazer a defini√ß√£o de score do `scikit-learn`, devemos usar o negativo do RMSE como score (por isso tem um `neg` na string que passamos no argumento `scoring`, vem de &ldquo;negativo&rdquo;). Basta voc√™ remover o sinal de negativo e ter√° seu RMSE tradicional como de costume. Sabendo disso, podemos dizer que o RMSE da valida√ß√£o cruzada do nosso modelo foi de 1441 d√≥lares.\n",
    "\n",
    "Agora, vamos ver o que acontece com o RMSE da valida√ß√£o cruzada quando aumentamos o n√∫mero de √°rvores de decis√£o de 10 para 100.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os scores foram de:  [-1341.55701171 -1394.39388685 -1352.1163828  -1369.27057055\n",
      " -1378.84199415 -1339.60033271 -1387.3036807  -1409.48832346\n",
      " -1445.31889204 -1427.7959096 ]\n",
      "\n",
      "A m√©dia dos scores √© de:  -1384.5686984565775\n"
     ]
    }
   ],
   "source": [
    "NUM_ARVORES = 100\n",
    "NUM_FOLDS = 10\n",
    "NUM_CPU_CORES = 4\n",
    "\n",
    "modelo_rf = RandomForestRegressor(\n",
    "    n_estimators=NUM_ARVORES,\n",
    "    random_state=SEMENTE_ALEATORIA,\n",
    "    n_jobs=NUM_CPU_CORES,\n",
    ")\n",
    "scores = cross_val_score(\n",
    "    modelo_rf,\n",
    "    X_treino,\n",
    "    y_treino,\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    ")\n",
    "\n",
    "print(\"Os scores foram de: \", scores)\n",
    "print()\n",
    "print(\"A m√©dia dos scores √© de: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O RMSE da valida√ß√£o cruzada deste modelo √© 1385 d√≥lares. Considerando apenas estes dois resultados, qual dos dois modelos voc√™ escolheria? Se respondeu o modelo com 100 √°rvores de decis√£o ent√£o voc√™ acertou! üéâ\n",
    "\n",
    "Observe que n√£o utilizamos o conjunto de teste at√© agora! Os scores foram computados apenas usando os dados de treino.\n",
    "\n",
    "Podemos repetir este procedimento quantas vezes quisermos para testar outras combina√ß√µes de modelos e hiperpar√¢metros. A maior limita√ß√£o dessa estrat√©gia √© que ela √© computacionalmente custosa&#x2026; uma estrat√©gia poss√≠vel para contornar essa desvantagem √© testar um grande n√∫mero de hiperpar√¢metros *sem* usar valida√ß√£o cruzada (apenas no conjunto de treino, como sempre!) e depois realizar a valida√ß√£o cruzada apenas para aqueles conjuntos de hiperpar√¢metros que tiverem a melhor performance.\n",
    "\n",
    "Vamos supor que fizemos isso e chegamos na conclus√£o que o melhor modelo para n√≥s √© de fato a floresta aleat√≥ria com 100 √°rvores de decis√£o e o restante dos hiperpar√¢metros com o valor padr√£o do `scikit-learn`. Agora, e somente agora, √© que n√≥s podemos usar nosso conjunto de teste para inferir a performance do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo floresta aleat√≥ria no conjunto de teste foi de 1384.6366214316938 d√≥lares.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "NUM_ARVORES = 100\n",
    "NUM_CPU_CORES = 4\n",
    "\n",
    "modelo_rf = RandomForestRegressor(\n",
    "    n_estimators=NUM_ARVORES,\n",
    "    random_state=SEMENTE_ALEATORIA,\n",
    "    n_jobs=NUM_CPU_CORES,\n",
    ")\n",
    "modelo_rf.fit(X_treino, y_treino)\n",
    "\n",
    "y_previsao = modelo_rf.predict(X_teste)\n",
    "RMSE = mean_squared_error(y_teste, y_previsao, squared=False)\n",
    "\n",
    "print(f\"O RMSE do modelo floresta aleat√≥ria no conjunto de teste foi de {RMSE} d√≥lares.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que o RMSE para o conjunto de teste foi de 1385 d√≥lares, similar ao que obtivemos na valida√ß√£o cruzada. Esse resultado √© bom no sentido que nossa estrat√©gia de valida√ß√£o cruzada conseguiu capturar bem a performance do modelo em dados que ele nunca viu (lembre-se que o conjunto de teste n√£o foi utilizado para nada at√© agora!). <u>Isso suporta a hip√≥tese de que n√£o houve overfit</u>. Observar√≠amos overfit caso a performance no conjunto de teste fosse significantemente pior que a performance na valida√ß√£o cruzada. N√£o √© nada usual a m√©trica no conjunto de teste ser significantemente melhor do que a obtida no conjunto de treino.\n",
    "\n",
    "Agora, esse resultado nos diz que nosso modelo √© um **bom modelo**? N√£o sei, isso vai depender se essa performance que obtivemos √© considerada boa dentro do universo onde os dados est√£o inseridos. Como muito provavelmente ningu√©m aqui √© um especialista em diamantes, √© dif√≠cil dizer se um RMSE de 1385 d√≥lares √© objetivamente bom ou ruim. Precisamos nos debru√ßar mais sobre o problema para responder essa pergunta com propriedade, mas uma opini√£o de leigo me sugere que n√£o √© um valor bom.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digamos que voc√™ queira fazer um estudo similar ao que fizemos acima, por√©m utilizando o modelo $k$-NN. Sabemos que o modelo $k$-NN √© baseado em dist√¢ncias e que modelos baseados em dist√¢ncias s√£o prejudicados quando os dados n√£o est√£o normalizados.\n",
    "\n",
    "Sabemos tamb√©m que n√£o podemos fazer nada com o conjunto de dados de teste at√© o final de *toda* a nossa an√°lise. Isso inclui o processo de normaliza√ß√£o! S√≥ podemos normalizar os dados considerando a informa√ß√£o dos dados de treino.\n",
    "\n",
    "Nosso processo aqui ent√£o √© um processo composto: normalizar e treinar um modelo.\n",
    "\n",
    "O `scikit-learn` tem uma forma de combinar processos chamada de `Pipeline` que atua como uma tubula√ß√£o de informa√ß√£o: a informa√ß√£o que entra no `Pipeline` √© transmitida para todas as componentes do `Pipeline` at√© o fim. Uma forma de criar um `Pipeline` √© usando o `make_pipeline` e passando para ele todas as componentes do modelo.\n",
    "\n",
    "Vamos ver um exemplo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os scores foram de:  [-1492.58797404 -1536.344317   -1490.72538853 -1519.26555191\n",
      " -1549.38567295 -1514.19954687 -1501.67522334 -1538.64171942\n",
      " -1599.10513296 -1549.31875221]\n",
      "\n",
      "A m√©dia dos scores √© de:  -1529.1249279225076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "NUM_VIZINHOS = 3\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "modelo_knn_composto = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    KNeighborsRegressor(n_neighbors=NUM_VIZINHOS),\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    modelo_knn_composto,\n",
    "    X_treino,\n",
    "    y_treino,\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    ")\n",
    "\n",
    "print(\"Os scores foram de: \", scores)\n",
    "print()\n",
    "print(\"A m√©dia dos scores √© de: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso `modelo_knn_composto` j√° cuida para n√≥s da normaliza√ß√£o (usando `MinMaxScaler`) e do ajuste do modelo $k$-NN. Vamos comparar esse modelo com $k=3$ vizinhos com um com $k=7$ vizinhos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os scores foram de:  [-1403.43840774 -1432.05381302 -1389.05961224 -1415.83127843\n",
      " -1443.82191369 -1408.20343265 -1424.81006271 -1460.45595828\n",
      " -1515.36550445 -1444.70361755]\n",
      "\n",
      "A m√©dia dos scores √© de:  -1433.7743600754025\n"
     ]
    }
   ],
   "source": [
    "NUM_VIZINHOS = 7\n",
    "NUM_FOLDS = 10\n",
    "\n",
    "modelo_knn_composto = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    KNeighborsRegressor(n_neighbors=NUM_VIZINHOS),\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    modelo_knn_composto,\n",
    "    X_treino,\n",
    "    y_treino,\n",
    "    cv=NUM_FOLDS,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    ")\n",
    "\n",
    "print(\"Os scores foram de: \", scores)\n",
    "print()\n",
    "print(\"A m√©dia dos scores √© de: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com $k=3$ vizinhos obtivemos um RMSE de 1529 d√≥lares na valida√ß√£o cruzada. J√° com $k=7$ obtivemos um RMSE menor de 1434 d√≥lares. Logo, ap√≥s esse experimento simples n√≥s concluimos que o modelo $k$-NN com $k=7$ vizinhos teve uma performance melhor e ser√° escolhido para ter a honra de prever o conjunto de teste. <u>Nota</u>: apenas dois experimentos √© muito pouco, devemos fazer mais! Mas aqui estamos apenas mostrando o racioc√≠nio.\n",
    "\n",
    "Para treinar um modelo composto n√≥s usamos o `fit` da mesma maneira que jÃÅa fizemos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O RMSE do modelo k-NN no conjunto de teste foi de 1436.3964946278834 d√≥lares.\n"
     ]
    }
   ],
   "source": [
    "NUM_VIZINHOS = 7\n",
    "\n",
    "modelo_knn_composto = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    KNeighborsRegressor(n_neighbors=NUM_VIZINHOS),\n",
    ")\n",
    "modelo_knn_composto.fit(X_treino, y_treino)\n",
    "\n",
    "y_previsao = modelo_knn_composto.predict(X_teste)\n",
    "RMSE = mean_squared_error(y_teste, y_previsao, squared=False)\n",
    "\n",
    "print(f\"O RMSE do modelo k-NN no conjunto de teste foi de {RMSE} d√≥lares.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente o RMSE do modelo no conjunto de teste foi muito similar ao RMSE obtido na valida√ß√£o cruzada. A mesma discuss√£o realizada acima cabe aqui.\n",
    "\n",
    "Para saber mais sobre `Pipelines`, veja a [documenta√ß√£o](https://scikit-learn.org/stable/modules/compose.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outros tipos de valida√ß√£o cruzada\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A valida√ß√£o $k$-fold √© a mais usual, por√©m existem outras estrat√©gias de valida√ß√£o cruzada. Algumas que valem a pena ter ci√™ncia:\n",
    "\n",
    "-   **Leave one out** (LOO): estrat√©gia similar √† valida√ß√£o $k$-fold, por√©m com o valor de $k$ sendo igual ao n√∫mero de exemplos dispon√≠veis. √â uma estrat√©gia interessante quando se tem poucos dados. [Documenta√ß√£o](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html).\n",
    "\n",
    "-   **Stratified $k$-fold**: estrat√©gia similar √† valida√ß√£o $k$-fold para ser usada em problemas de classifica√ß√£o. A ideia √© manter a propor√ß√£o dos r√≥tulos quando se efetuar a divis√£o dos folds. √â particularmente boa em conjuntos de dados desbalanceados (isto √©, com quantidades significativamente diferentes dos r√≥tulos). [Documenta√ß√£o](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html).\n",
    "\n",
    "-   **Time series split**: estrat√©gia para se dividir s√©ries temporais. A ideia √© que cada segmenta√ß√£o dos dados n√≥s teremos um conjunto de teste que formam um bloco no eixo do tempo. Todos os dados com tempo menor do que os do bloco de teste s√£o considerados o conjunto de treino. Todos os dados com tempo maior que o conjunto de teste n√£o s√£o considerados neste split. Veja a imagem abaixo. Se seus dados variam ao longo do tempo, ent√£o √© melhor utilizar esta estrat√©gia do que a valida√ß√£o $k$-fold. [Documenta√ß√£o](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html).\n",
    "\n",
    "![img](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_013.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XKCD relevante\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://imgs.xkcd.com/comics/significant.png)\n",
    "\n",
    "`Imagem: Significant (XKCD) dispon√≠vel em https://xkcd.com/882`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refer√™ncias e leitura adicional\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  [https://scikit-learn.org/stable/modules/cross_validation.html](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "2.  [https://scikit-learn.org/stable/modules/compose.html](https://scikit-learn.org/stable/modules/compose.html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
